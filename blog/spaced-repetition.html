<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <title>Jesung Park</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="Personal website of Jesung Park">
  <meta name="author" content="Jesung Park">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-ZNQ01YG9MY"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-ZNQ01YG9MY');
  </script>

  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-WHH4ZFP');</script>
  <!-- End Google Tag Manager -->

  <!--CSS-->
  <link rel="stylesheet" href="../assets/css/w3.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Raleway">
  <link rel="stylesheet" href="../assets/css/all.css">
  <link rel="stylesheet" href="../assets/css/main.css">
  <style>
    body,h1,h2,h3,h4,h5,h6 {font-family: "Raleway", sans-serif}
  </style>

  <link rel="shortcut icon" type="image/ico" href="../assets/ico/j-icon.ico">
  <link rel="icon" type="image/x-icon" href="../assets/ico/j-icon.ico">

  <!--MathJax-->
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
        chtml: { displayAlign: 'left' }
    };
  </script>
  </script>
  <script id="MathJax-script" async
          src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>

</head>

<body class="w3-light-grey w3-content Site" style="max-width:1600px">
  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WHH4ZFP"
  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->

  <!-- Sidebar/menu -->
  <nav class="w3-sidebar w3-collapse w3-white w3-animate-left" style="z-index:3;width:300px;" id="mySidebar"><br>
    <div class="w3-container">
      <a href="#" onclick="w3_close()" class="w3-hide-large w3-right w3-jumbo w3-padding w3-hover-grey" title="close menu">
        <i class="fa fa-remove"></i>
      </a>
      <img src="../assets/img/about/chump.jpg" style="width:95%;" class="w3-round"><br><br>
      <h4><b>Jesung Park</b></h4>
      <p class="w3-text-grey">A collection of random projects and musings</p>
    </div>
    <div class="w3-bar-block">
      <a href="../about.html" onclick="w3_close()" class="w3-bar-item w3-button w3-padding"><i class="fa fa-user fa-fw w3-margin-right"></i>ABOUT</a>
      <a href="../index.html" onclick="w3_close()" class="w3-bar-item w3-button w3-padding w3-text-teal"><i class="fab fa-microblog fa-fw w3-margin-right"></i>BLOG</a>
      <a href="../projects.html" onclick="w3_close()" class="w3-bar-item w3-button w3-padding"><i class="fa fa-th-large fa-fw w3-margin-right"></i>PROJECTS</a>
    </div>
    <div class="w3-panel w3-large">
      <a href="https://www.linkedin.com/in/jesungpark/" target="_blank"><i class="fab fa-linkedin fa-fw fa-2x w3-hover-opacity"></i></a>
      <a href="https://github.com/jesung" target="_blank"><i class="fab fa-github fa-fw fa-2x w3-hover-opacity"></i></a>
    </div>
  </nav>

  <!-- Overlay effect when opening sidebar on small screens -->
  <div class="w3-overlay w3-hide-large w3-animate-opacity" onclick="w3_close()" style="cursor:pointer" title="close side menu" id="myOverlay"></div>

  <!-- !PAGE CONTENT! -->
  <div class="w3-main Site-content" style="margin-left:300px">

        <!-- Header -->
        <header id="portfolio">
          <a href="#"><img src="../assets/img/about/chump.jpg" style="width:65px;" class="w3-circle w3-right w3-margin w3-hide-large w3-hover-opacity"></a>
          <span class="w3-button w3-hide-large w3-xxlarge w3-hover-text-grey" onclick="w3_open()"><i class="fa fa-bars"></i></span>
          <div class="w3-container">
            <br>
            <h1><b>Spaced repetition – how to create lasting memory</b></h1>

            <div class="w3-section w3-bottombar w3-padding-4">
              <!--<span class="w3-margin-right">Filter:</span>
              <button class="w3-button w3-black">ALL</button>
              <button class="w3-button w3-white"><i class="fa fa-diamond w3-margin-right"></i>Design</button>
              <button class="w3-button w3-white w3-hide-small"><i class="fa fa-photo w3-margin-right"></i>Photos</button>
              <button class="w3-button w3-white w3-hide-small"><i class="fa fa-map-pin w3-margin-right"></i>Art</button>
              -->
            </div>
          </div>
        </header>

        <!-- Article body-->
        <article class="w3-row-padding">
          <div class="clearfix">
          </div>
          <!-- explanation -->

          <div class="w3-full w3-container w3-margin-bottom">
            <p>
              If you ever tried to learn a new language, building up sufficient vocabulary to have basic conversations is one of the biggest hurdles. You can memorize basic sentences but will not know what to say when the conversation goes off script. Even more challenging, what the heck is the other person saying? I have ended many a conversation with 我不知道 (I don't know) or 我不明白你说什么 (I don't understand what you're saying) because my Mandarin Chinese vocabulary is so limited.
            </p>
            <p>
              Given the huge amount of time required to study languages, what is the most efficient way to memorize and recall a long list of facts? The answer is <b>spaced repetition</b>. Spaced repetition is a technique where the <u>time intervals between active recall get increasingly longer</u> as your memory strengthens. This technique applies to broader topics such as studying for exams, quotes you want to remember<sup>1</sup>, and even learning coding languages as long as the information can be broken down into bite-sized chunks. For reasons that I will not dive into here, <b>active recall</b> is more effective at strengthening memory compared to passive review.
            </p>
          </div>
          <div class="blank10"></div>
          <!-- simulation -->
          <div class="span12">
            <h4>Ebbinghaus' forgetting curve</h4>
          </div>
          <div class="w3-full w3-container w3-margin-bottom">
            <p>
              The foundation of spaced repetition is often attributed to the German psychologist Hermann Ebbinghaus<sup>2</sup>, who ran a N=1 study on himself in the 1880s to remember nonsense syllables. Focusing on nonsense consonant-vowel-consonant syllables such as KOJ and YAT instead of words people can reference such as DOT or LAW was Ebbinghaus' attempt at removing any existing knowledge of language from the equation. This led to him publishing the forgetting curve<sup>3</sup> in 1885 which is simplified in a recent paper (Reddy et al., 2016)<sup>4</sup>. The formula is fairly simple:
              \[P[ \textrm{recall} ] = \exp (-\theta \cdot \frac{d}{s})\]
              where \(\theta \in \mathbb{R}^+ \) is the item difficulty, \(d \in \mathbb{R}^+ \) is the delay or time elapsed since previous review, and \(s \in \mathbb{R}^+ \) is the memory strength.
            </p>
            <div class="w3-container w3-margin-bottom">
              <small>
                <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/4e/ForgettingCurve.svg/1200px-ForgettingCurve.svg.png" alt="ForgettingCurve.svg" style="width:50%"><br>By <a href="https://en.wikipedia.org/wiki/User:Icez" class="extiw" title="wikipedia:User:Icez">Icez</a> at <a href="https://en.wikipedia.org/wiki/" class="extiw" title="wikipedia:">English Wikipedia</a>. - Originally from <a class="external text" href="https://en.wikipedia.org">en.wikipedia</a>; description page is/was
                <a class="external text" href="https://en.wikipedia.org/w/index.php?title=Image:ForgettingCurve.svg">here</a>., Public Domain, <a href="https://commons.wikimedia.org/w/index.php?curid=2214107">Link</a>
              </small>
            </div>
            <p>
              As you can see above, the curve has an exponential decay and will shift depending on item difficulty, time since last review, and memory strength. If the item was just learned (\(d=0\)), then \(P[\mathrm{recall}] = 1\). On the other hand, if the item was learned a long time ago, then \(P[\mathrm{recall}]\) will approach 0.
            </p>
          </div>
          <div class="span12">
            <h4>Leitner system</h4>
          </div>
          <div class="w3-full w3-container w3-margin-bottom">
            <p>
              Fast forward nearly a century, the German science journalist Sebastian Leitner proposed a method based on spaced repetition in his book <i>So lernt man Lernen</i> (How to learn to learn) in 1972<sup>5</sup>. This method uses 5 boxes of increasing size (1, 2, 5, 8 and 14 cm) where the flashcards within each box were reviewed only if it was full. During review, correctly answered cards will graduate to the next box while incorrectly answered cards will go back to the first box.
            </p>
            <div class="w3-container w3-margin-bottom">
              <small>
                <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/82/Leitner_system_alternative.svg/1200px-Leitner_system_alternative.svg.png" alt="Leitner system alternative.svg" style="width:50%"><br>By <a href="//commons.wikimedia.org/wiki/User:Zirguezi" title="User:Zirguezi">Zirguezi</a> - <span class="int-own-work" lang="en">Own work</span>, <a href="http://creativecommons.org/publicdomain/zero/1.0/deed.en" title="Creative Commons Zero, Public Domain Dedication">CC0</a>, <a href="https://commons.wikimedia.org/w/index.php?curid=20328125">Link</a>
              </small>
            </div>
            <p>
              This system ensures that the more difficult flashcards are reviewed more frequently which results in efficient time use. However, it may take a long time to fill up the last box at which point the first card in the box may be significantly older than the last card. How can you space out the reviews at an individual card level to take advantage of the <b>optimal repetition spacing</b>?
            </p>
          </div>
          <div class="span12">
            <h4>SuperMemo</h4>
          </div>
          <div class="w3-full w3-container w3-margin-bottom">
            <p>
              In 1985, Polish researcher Piotr Wozniak developed the first iteration of the SuperMemo algorithm SM-0 that loosely followed Leitner’s methods<sup>6</sup>. By 1987, this evolved into SM-2 - a computer algorithm at the individual card level with the following interval algorithm<sup>7</sup>.
            </p>
            <p>
              \[ I(1) \rightarrow 1 \]
              \[ I(2) \rightarrow 6 \]
              \(I(n) \rightarrow I(n-1) \cdot \textrm{EF} \) for \( n>2 \)
              <br>where \( I(n) \) is the inter-repetition interval after the \( n \)-th repetition
              <br>and \( \textrm{EF} \) is the easiness factor reflecting the easiness of memorizing and retaining a given item in memory.
            <p>
              While the latest version of the SuperMemo algorithm is up to SM-18, a variant of SM-2 is still used in the popular open-source flashcard program Anki. These algorithms may be crude but there is no disputing the success people have had with spaced repetition software. Spaced repetition is the backbone of many language acquisition programs such as Pimsleur and Duolingo.
            </p>
          </div>
          <div class="span12">
            <h4>Challenges</h4>
          </div>
          <div class="w3-full w3-container w3-margin-bottom">
            <p>
              Tools like SuperMemo and Anki are a significant step up from the traditional methods but they are heuristic based approaches that use hand-picked weights. Looking back to the evolution of various disciplines within machine learning (e.g. natural language processing, computer vision), they started with a lot of structures and assumptions, including hand-picked features. As computing power, available data, and our understanding of these disciplines improved, the models got rid of more assumptions.<sup>9</sup>
            </p>
            <p>
              With the massive amount of data that are being collected by spaced repetition software and technological progress since the 80s, leveraging machine learning approaches for optimizing to the best policy starts make sense. We explore two different ML-based approaches: half-life regression and Leitner queue network.
            </p>
          </div>
          <div class="span12">
            <h4>Half-life regression</h4>
          </div>
          <div class="w3-full w3-container w3-margin-bottom">
            <p>
              Settles et al. (2016)<sup>8</sup> goes back to basics with Ebbinghaus’ forgetting curve.
              \[ p = 2 ^{-\Delta/h} \]
              In this equation, \( p \) denotes the probability of correctly recalling an item which is a function of \( \Delta \), the <i>lag time</i> since the item was last practiced, and \( h \) is the <i>half-life</i> or measure of strength in the learner's long-term memory
            </p>
            <p>
              We can then estimate the half-life with
              \( \hat{h}_\Theta = 2^{\Theta \cdot x} \)
              where \( x \) is the student's feature vector and \( \Theta \) is the set of weights that correspond to the features.
              <br>Features broadly fell into two categories:
              <ol>
                <li>Interaction features that count the student's history with a certain word</li>
                <li>Lexeme tag features which is a sparse matrix of roughly twenty thousand lexeme tags to capture the inherent difficulty of the word</li>
              </ol>
            </p>
            <p>
              The model then predicts \( \hat{p}_\Theta = 2^{- \Delta / \hat{h}_{\Theta}} \) with loss function \( \ell (X; \Theta) = (p - \hat{p}_\Theta)^2 + \alpha (h - \hat{h}_\Theta)^2 + \lambda \| \Theta \|^2_2 \)
              where \( X = \langle p, \Delta, x \rangle \) and \( \lambda \) is the regularization term.
            </p>
            <p>
              Results of the model was positive with the half-life (HLR) model significantly improving upon the mean absolute error (MAE) and getting very close in the area under the curve (AUC) compared to the baseline. The authors observed <b>two insights</b>:
              <ol>
                <li>Including the lexeme tag features did not make a significant difference to the results</li>
                <li>Optimizing for the half-life (\( \hat{h} \)) is clearly important to the model</li>
              </ol>
            </p>
            <p>
              When the model was implemented into the production system of Duolingo where Settles worked, they found that the lexeme tag features were possibly overfitting for difficult words. To skirt around this as well as the <a href="https://en.wikipedia.org/wiki/Cold_start_(recommender_systems)" target="_blank">cold-start problem</a>, Duolingo removed the lexeme tag features and saw statistically significant improvement in retention metrics over the original Leitner system.
            </p>
          </div>
          <div class="span12">
            <h4>Leitner queue network</h4>
          </div>
          <div class="w3-full w3-container w3-margin-bottom">
            <p>
              In Reddy et al. (2016) on the other hand, the Leitner system is taken to the next level. For deck \( k \) at time \( t \), let \( D_k=t-T_{k,1} \) denote the delay since the last review of that item. Then we have the transition probability
              \[P [k \rightarrow k + 1] = \exp{ (- \theta \cdot D_k / k) } \]
              \[P [k \rightarrow \max \{k - 1, 1 \}] = 1 - \exp{(- \theta \cdot D_k / k)} \]
              Note that the term \(\theta \cdot D_k / k \) is equivalent to \( \Delta / h \) in half-life regression. They both describe how quickly the probability of recall degrades over time.
            </p>
            <p>
              We can then define the problem as finding the scheduling policy that maximizes the learning rate
              \[ \lambda_{\textrm{out}} = \lim_{T\to\infty} \frac{1}{T} \cdot |  \{ \textrm{Items mastered in interval [0,T]} \} | \]
              given a static arrival rate \( \lambda_{\textrm{ext}} \) that follows a Poisson distribution, a service rate \( \mu_k \) representing the rate at which items from deck \( k \) come up for review, and the user’s review frequency constraint \( \lambda_{\textrm{ext}} + \sum_k \mu_k \le U \).
            </p>
            <p>
              From both the theory as well the experiments, a few interesting observations emerge:
              <ul>
                <li>Given a fixed review frequency budget \( U \), there is a phase transition in learning where your throughput (\( \lambda_{\mathrm{out}} \)) initially increases fairly linearly with arrival rate (\( \lambda_{\mathrm{ext}} \)) but starts to nose-dive as the arrival rate overwhelms the review frequency budget. As such, there is an optimal arrival rate for ever throughput.</li>
                <li>As a corollary, as your review frequency budget increases, your optimal arrival rate will increase fairly linearly.</li>
                <li>Item difficulty has a big impact on optimal review schedules. The more difficult the material, you should introduce new material less often and spend more time on newer material.</li>
              </ul>
          </div>
          <div class="span12">
            <h4>Conclusion</h4>
          </div>
          <div class="w3-full w3-container w3-margin-bottom">
            <p>
              These newer algorithms are certainly an improvement over their 3-4 decade-old parents but not without challenges. In half-life regression, the measured probability of recall is at the session level. This drops the temporal aspect (forgetting at the beginning is better than forgetting at the end) and the magnitude (getting 1/1 vs. 10/10) which are arguably useful information to bake in. On the other hand, Leitner queue network uses approximate methods to make the problem tractable which may impact accuracy and the FIFO structure does not allow for cards to reshuffle within a deck or move between decks without review.
            </p>
            <p>
              Despite their challenges, any version of these spaced repetition algorithms is a significant step up from the other approaches such as random review or focusing on recent cards10. That being said, these approaches make you more efficient with your time but they are not a substitute for hard work. You need to put in the effort and create habits to make the effort sustainable. Following the theme of quotes I want to remember, I will end with this:
              <blockquote><i>Nothing in the world is worth having or worth doing unless it means effort, pain, difficulty… I have never in my life envied a human being who led an easy life. I have envied a great many people who led difficult lives and led them well.
                <br>-Theodore Roosevelt</i>
              </blockquote>
            </p>
          </div>

          <div class="w3-full w3-container w3-margin-bottom">
            <p>
              <i><sup>1</sup><small>I recently learned the full quote of Oscar Wilde's oft-quoted "Imitation is the sincerest form of flattery" (<a href="https://www.goodreads.com/quotes/558084-imitation-is-the-sincerest-form-of-flattery-that-mediocrity-can" target="_blank">full quote here</a>)</small></i>
              <br>
              <i><sup>2</sup><small>Herman Ebbinghaus. (n.d). In Wikipedia. https://en.wikipedia.org/wiki/Hermann_Ebbinghaus, accessed December 16, 2020</small></i>
              <br>
              <i><sup>3</sup><small>Forgetting Curve. (n.d). In Wikipedia. https://en.wikipedia.org/wiki/Forgetting_curve, accessed December 16, 2020</small></i>
              <br>
              <i><sup>4</sup><small>Reddy, S. et al. 2016. Unbounded Human Learning: Optimal Scheduling for Spaced Repetition. https://dl.acm.org/doi/pdf/10.1145/2939672.2939850</small></i>
              <br>
              <i><sup>5</sup><small>Leitner, S. (1972). So lernt man lernen. Herder.</small></i>
              <br>
              <i><sup>6</sup><small>Wozniak, P. 1990. https://www.supermemo.com/en/archives1990-2015/english/ol/beginning#Algorithm, accessed December 17, 2020</small></i>
              <br>
              <i><sup>7</sup><small>Wozniak, P. 1990. https://www.supermemo.com/en/archives1990-2015/english/ol/sm2, accessed December 18, 2020</small></i>
              <br>
              <i><sup>8</sup><small>Settles, B., Meeder, B. 2016. A Trainable Spaced Repetition Model for Language Learning. https://www.aclweb.org/anthology/P16-1174.pdf </small></i>
              <br>
              <i><sup>9</sup><small>For a more recent example, look at the various iterations of AlphaGo. It first learned from human games, then learned to play from scratch (AlphaZero), then learned without even knowing the rules of the game (MuZero) - with each version surpassing its predecessor.</small></i>
              <br>
              <i><sup>10</sup><small>AndrewFMs. (November 19, 2011). Simulation of SRS vs. Traditional Review [Video] YouTube. https://www.youtube.com/watch?v=ai2K3qHpC7c&ab_channel=AndrewFMs</small></i>
            </p>
          </div>
        </article>
  </div>

  <!-- Footer -->
  <footer>
    <div class="w3-black w3-center w3-padding-24">
      <a href="https://www.linkedin.com/in/jesungpark/" target="_blank"><i class="fab fa-linkedin fa-fw fa-2x w3-hover-opacity"></i></a>
      <a href="https://github.com/jesung" target="_blank"><i class="fab fa-github fa-fw fa-2x w3-hover-opacity"></i></a>
    </div>
  </footer>
  <!-- End page content -->


  <script>
  // Script to open and close sidebar
  function w3_open() {
    document.getElementById("mySidebar").style.display = "block";
    document.getElementById("myOverlay").style.display = "block";
  }

  function w3_close() {
    document.getElementById("mySidebar").style.display = "none";
    document.getElementById("myOverlay").style.display = "none";
  }
</script>

</body>
</html>
